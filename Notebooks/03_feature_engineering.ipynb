{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4446c4a-2884-4e06-8d4a-1d9f49c45a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FEATURE ENGINEERING FOR CHURN PREDICTION\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "PART 1: LOADING DATA\n",
      "======================================================================\n",
      "✅ Loaded 5,000 customer records\n",
      "   Original features: 18\n",
      "Features engineered: (5000, 35)\n",
      "  customer_id signup_date  tenure_days subscription_tier  \\\n",
      "0  cust_00000  2025-04-22          132             basic   \n",
      "1  cust_00001  2025-05-03          121              free   \n",
      "2  cust_00002  2024-07-19          409              free   \n",
      "3  cust_00003  2024-01-27          583              free   \n",
      "4  cust_00004  2023-11-09          662             basic   \n",
      "\n",
      "   monthly_reoccuring_revenue company_size industry  logins_30d  \\\n",
      "0                          49         1-10   retail          23   \n",
      "1                           0         1-10  finance          21   \n",
      "2                           0         1-10     tech          19   \n",
      "3                           0         1-10    other          23   \n",
      "4                          49       51-200     tech          15   \n",
      "\n",
      "   session_duration_avg  features_used  ...  sentiment_risk  \\\n",
      "0                  33.9              5  ...               0   \n",
      "1                  44.4              3  ...               0   \n",
      "2                  39.1              9  ...               0   \n",
      "3                  50.7              8  ...               0   \n",
      "4                  40.4              5  ...               0   \n",
      "\n",
      "   support_quality_score  satisfaction_index  value_realization  \\\n",
      "0               0.909091               0.585               0.25   \n",
      "1               1.000000               0.790               0.15   \n",
      "2               0.818182               0.540               0.45   \n",
      "3               1.000000               0.815               0.40   \n",
      "4               0.909091               0.550               0.25   \n",
      "\n",
      "   revenue_risk_score  estimated_ltv  engagement_tenure  recency_score  \\\n",
      "0                   0     215.600000         101.200000       1.000000   \n",
      "1                   0     197.633333          84.700000       0.500000   \n",
      "2                   0     668.033333         259.033333       0.090909   \n",
      "3                   0     952.233333         446.966667       1.000000   \n",
      "4                   0    1081.266667         331.000000       1.000000   \n",
      "\n",
      "   usage_efficiency  engagement_ratio  \n",
      "0          0.143266             12.19  \n",
      "1          0.066079             11.55  \n",
      "2          0.224439             15.01  \n",
      "3          0.154739             17.48  \n",
      "4          0.120773             14.10  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "\n",
      "======================================================================\n",
      "PART 2: CREATING ENGAGEMENT FEATURES\n",
      "======================================================================\n",
      "\n",
      "Engineering composite engagement metrics...\n",
      "✅ Created: engagement_score (weighted composite)\n",
      "✅ Created: activity_recency (recency metric)\n",
      "✅ Created: usage_efficiency (features per login)\n",
      "✅ Created: power_user_score (advanced usage metric)\n",
      "✅ Created: engagement_velocity (trend indicator)\n",
      "\n",
      "======================================================================\n",
      "PART 3: CREATING CUSTOMER HEALTH FEATURES\n",
      "======================================================================\n",
      "\n",
      "Engineering customer health scores...\n",
      "✅ Created: health_score (0-100 composite)\n",
      "✅ Created: 6 risk flag features\n",
      "✅ Created: lifecycle_stage (categorical)\n",
      "\n",
      "======================================================================\n",
      "PART 4: CREATING SUPPORT & SATISFACTION FEATURES\n",
      "======================================================================\n",
      "\n",
      "Engineering support interaction features...\n",
      "✅ Created: support_intensity (tickets per month of tenure)\n",
      "✅ Created: support_quality_score (0-100)\n",
      "✅ Created: nps_category (promoter/passive/detractor)\n",
      "✅ Created: satisfaction_index (0-100)\n",
      "\n",
      "======================================================================\n",
      "PART 5: CREATING USAGE & VALUE FEATURES\n",
      "======================================================================\n",
      "\n",
      "Engineering usage and value features...\n",
      "✅ Created: usage_category (low/medium/high)\n",
      "✅ Created: value_realization (usage × engagement)\n",
      "✅ Created: revenue_risk_score (Monthly Reoccuring Revenue-weighted risk)\n",
      "✅ Created: estimated_ltv (projected lifetime value)\n",
      "\n",
      "======================================================================\n",
      "PART 6: CREATING INTERACTION FEATURES\n",
      "======================================================================\n",
      "\n",
      "Engineering feature interactions...\n",
      "✅ Created: engagement_tenure (engagement × log(tenure))\n",
      "✅ Created: usage_satisfaction (usage × sentiment)\n",
      "✅ Created: login_feature_interaction (logins × features)\n",
      "✅ Created: subscription_tier_engagement (subscription_tier × engagement)\n",
      "\n",
      "======================================================================\n",
      "PART 7: CREATING TIME-BASED FEATURES\n",
      "======================================================================\n",
      "\n",
      "Engineering temporal features...\n",
      "✅ Created: tenure_segment (7 categories)\n",
      "✅ Created: tenure_velocity (engagement per day)\n",
      "✅ Created: recently_active (binary flag)\n",
      "✅ Created: stale_account (binary flag)\n",
      "\n",
      "======================================================================\n",
      "PART 8: ENCODING CATEGORICAL FEATURES\n",
      "======================================================================\n",
      "\n",
      "Encoding categorical variables for modeling...\n",
      "✅ Encoded: subscription_tier → tier_encoded\n",
      "   Mapping: {'basic': np.int64(0), 'free': np.int64(1), 'premium': np.int64(2)}\n",
      "✅ Encoded: company_size → size_encoded\n",
      "   Mapping: {'1-10': np.int64(0), '11-50': np.int64(1), '200+': np.int64(2), '51-200': np.int64(3)}\n",
      "✅ Encoded: industry → industry_encoded\n",
      "   Mapping: {'finance': np.int64(0), 'healthcare': np.int64(1), 'other': np.int64(2), 'retail': np.int64(3), 'tech': np.int64(4)}\n",
      "✅ Encoded: lifecycle_stage → lifecycle_encoded\n",
      "✅ Encoded: net_promoter_score_category → net_promoter_score_category_encoded\n",
      "✅ Encoded: usage_category → usage_category_encoded\n",
      "\n",
      "======================================================================\n",
      "PART 9: FEATURE ENGINEERING SUMMARY\n",
      "======================================================================\n",
      "\n",
      "📊 Feature Engineering Results:\n",
      "   • Original features: 18\n",
      "   • New features created: 36\n",
      "   • Total features: 54\n",
      "\n",
      "✨ New Features by Category:\n",
      "\n",
      "   Engagement Features (8):\n",
      "   • engagement_score\n",
      "   • activity_recency\n",
      "   • usage_efficiency\n",
      "   • power_user_score\n",
      "   • engagement_velocity\n",
      "   • low_engagement_risk\n",
      "   • engagement_tenure\n",
      "   • subscription_tier_engagement\n",
      "\n",
      "   Health & Risk Features (8):\n",
      "   • health_score\n",
      "   • dormancy_risk\n",
      "   • low_engagement_risk\n",
      "   • support_risk\n",
      "   • payment_risk\n",
      "   • sentiment_risk\n",
      "   • high_risk_flag\n",
      "   • revenue_risk_score\n",
      "\n",
      "   Support & Satisfaction Features (7):\n",
      "   • support_risk\n",
      "   • support_intensity\n",
      "   • support_quality_score\n",
      "   • net_promoter_score_category\n",
      "   • satisfaction_index\n",
      "   • usage_satisfaction\n",
      "   • net_promoter_score_category_encoded\n",
      "\n",
      "   Value Features (3):\n",
      "   • value_realization\n",
      "   • revenue_risk_score\n",
      "   • estimated_ltv\n",
      "\n",
      "   Interaction Features (12):\n",
      "   • power_user_score\n",
      "   • low_engagement_risk\n",
      "   • high_risk_flag\n",
      "   • support_quality_score\n",
      "   • net_promoter_score_category\n",
      "   • revenue_risk_score\n",
      "   • login_feature_interaction\n",
      "   • subscription_tier_numeric\n",
      "   • subscription_tier_engagement\n",
      "   • subscription_tier_encoded\n",
      "   • net_promoter_score_category_encoded\n",
      "   • usage_category_encoded\n",
      "\n",
      "======================================================================\n",
      "PART 10: ANALYZING NEW FEATURE CORRELATIONS\n",
      "======================================================================\n",
      "\n",
      "🎯 Top 20 Features by Correlation with Churn:\n",
      "----------------------------------------------------------------------\n",
      " 1. 🔴 low_engagement_risk                  0.969 ↑ ✨ NEW\n",
      " 2. 🔴 high_risk_flag                       0.967 ↑ ✨ NEW\n",
      " 3. 🔴 health_score                        -0.862 ↓ ✨ NEW\n",
      " 4. 🔴 logins_30d                          -0.844 ↓ \n",
      " 5. 🔴 login_feature_interaction           -0.725 ↓ ✨ NEW\n",
      " 6. 🔴 engagement_score                    -0.698 ↓ ✨ NEW\n",
      " 7. 🔴 value_realization                   -0.686 ↓ ✨ NEW\n",
      " 8. 🔴 usage_satisfaction                  -0.684 ↓ ✨ NEW\n",
      " 9. 🔴 usage_vs_plan                       -0.678 ↓ \n",
      "10. 🔴 engagement_tenure                   -0.676 ↓ ✨ NEW\n",
      "11. 🔴 features_used                       -0.638 ↓ \n",
      "12. 🔴 engagement_velocity                 -0.619 ↓ ✨ NEW\n",
      "13. 🔴 recently_active                     -0.575 ↓ ✨ NEW\n",
      "14. 🔴 days_since_last_login                0.564 ↑ \n",
      "15. 🔴 dormancy_risk                        0.549 ↑ ✨ NEW\n",
      "16. 🟡 usage_efficiency                     0.492 ↑ ✨ NEW\n",
      "17. 🟡 session_duration_avg                -0.472 ↓ \n",
      "18. 🟡 sentiment_risk                       0.442 ↑ ✨ NEW\n",
      "19. 🟡 satisfaction_index                  -0.438 ↓ ✨ NEW\n",
      "20. 🟡 net_promoter_score                  -0.413 ↓ \n",
      "\n",
      "======================================================================\n",
      "PART 11: CREATING FEATURE VISUALIZATIONS\n",
      "======================================================================\n",
      "\n",
      "✅ Saved visualization: ../Datasets/feature_engineering_analysis.png\n",
      "\n",
      "======================================================================\n",
      "PART 12: SAVING ENGINEERED DATASET\n",
      "======================================================================\n",
      "\n",
      "✅ Saved engineered dataset: ../Datasets/customer_churn_engineered.csv\n",
      "   Shape: 5,000 rows × 54 columns\n",
      "   Size: 3.08 MB\n",
      "✅ Saved feature metadata: ../data/feature_info.pkl\n",
      "\n",
      "======================================================================\n",
      "PART 13: FEATURE SELECTION RECOMMENDATIONS\n",
      "======================================================================\n",
      "\n",
      "📋 Recommended Feature Sets:\n",
      "\n",
      "1️⃣  MINIMAL SET (Top 10 - Quick Model):\n",
      "    1. low_engagement_risk\n",
      "    2. high_risk_flag\n",
      "    3. health_score\n",
      "    4. logins_30d\n",
      "    5. login_feature_interaction\n",
      "    6. engagement_score\n",
      "    7. value_realization\n",
      "    8. usage_satisfaction\n",
      "    9. usage_vs_plan\n",
      "   10. engagement_tenure\n",
      "\n",
      "2️⃣  STANDARD SET (Top 20 - Balanced):\n",
      "   20 features including engagement, health, and risk metrics\n",
      "\n",
      "3️⃣  COMPREHENSIVE SET (All Numeric - Maximum Performance):\n",
      "   44 features - all engineered numeric features\n",
      "\n",
      "4️⃣  INTERPRETABLE SET (Easy to Explain):\n",
      "    1. health_score\n",
      "    2. engagement_score\n",
      "    3. high_risk_flag\n",
      "    4. days_since_last_login\n",
      "    5. logins_30d\n",
      "    6. support_tickets_30d\n",
      "    7. net_promoter_score\n",
      "    8. usage_vs_plan\n",
      "    9. payment_failures\n",
      "   10. tenure_days\n",
      "\n",
      "======================================================================\n",
      "✅ FEATURE ENGINEERING COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Feature Engineering Summary:\n",
      "  • Original features: 18\n",
      "  • New features created: 36\n",
      "  • Total features: 54\n",
      "  • Numeric features for modeling: 44\n",
      "  \n",
      "Feature Categories Created:\n",
      "  • Engagement metrics: 8\n",
      "  • Health & risk indicators: 8\n",
      "  • Support & satisfaction: 7\n",
      "  • Value metrics: 3\n",
      "  • Interaction features: 12\n",
      "  \n",
      "Top Predictors Identified:\n",
      "  1. low_engagement_risk: 0.969\n",
      "  2. high_risk_flag: 0.967\n",
      "  3. health_score: 0.862\n",
      "  \n",
      "Files Created:\n",
      "  1. customer_churn_engineered.csv (full dataset)\n",
      "  2. feature_info.pkl (feature metadata)\n",
      "  3. feature_engineering_analysis.png (9 visualizations)\n",
      "\n",
      "\n",
      "🚀 Ready for Model Training!\n",
      "======================================================================\n",
      "PART 1: LOADING DATA\n",
      "======================================================================\n",
      "✅ Loaded 5,000 customer records\n",
      "   Original features: 18\n"
     ]
    }
   ],
   "source": [
    "### Notebook 3: Feature Engineering\n",
    "### Project: Churn Prevention System\n",
    "### This notebook creates advanced features for better predictions\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "### Add the Dashboards folder to Python's search path\n",
    "dashboards_path = os.path.abspath(os.path.join('..', 'Dashboards'))\n",
    "sys.path.insert(0, dashboards_path)\n",
    "\n",
    "# sys.path.append('..')  # Go up to project root\n",
    "\n",
    "from feature_engineering import engineer_features\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"FEATURE ENGINEERING FOR CHURN PREDICTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "### =============================================================================\n",
    "### PART 1: LOAD DATA\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 1: LOADING DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "df = pd.read_csv('../Datasets/customer_churn_data.csv')\n",
    "print(f\"✅ Loaded {len(df):,} customer records\")\n",
    "print(f\"   Original features: {len(df.columns)}\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 1.5: ENGINEERING FEATURES\n",
    "### =============================================================================\n",
    "\n",
    "df_processed = engineer_features(df)\n",
    "print(f\"Features engineered: {df_processed.shape}\")\n",
    "print(df_processed.head())\n",
    "\n",
    "### =============================================================================\n",
    "### PART 2: ENGAGEMENT FEATURES\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 2: CREATING ENGAGEMENT FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nEngineering composite engagement metrics...\")\n",
    "\n",
    "### 1. Overall Engagement Score\n",
    "### Weighted combination of key engagement metrics\n",
    "df['engagement_score'] = (\n",
    "    df['logins_30d'] * 0.3 +\n",
    "    df['features_used'] * 0.3 +\n",
    "    df['session_duration_avg'] * 0.2 +\n",
    "    df['power_feature_usage'] * 0.2\n",
    ")\n",
    "print(\"✅ Created: engagement_score (weighted composite)\")\n",
    "\n",
    "### 2. Activity Recency Score\n",
    "### Inverse of days since last login (normalized)\n",
    "df['activity_recency'] = 1 / (df['days_since_last_login'] + 1)\n",
    "print(\"✅ Created: activity_recency (recency metric)\")\n",
    "\n",
    "### 3. Usage Efficiency\n",
    "### How efficiently customers use the product (features per login)\n",
    "df['usage_efficiency'] = df['features_used'] / (df['logins_30d'] + 1)\n",
    "print(\"✅ Created: usage_efficiency (features per login)\")\n",
    "\n",
    "### 4. Power User Score\n",
    "### Combination of advanced feature usage and frequency\n",
    "df['power_user_score'] = (\n",
    "    df['power_feature_usage'] * df['logins_30d']\n",
    ") / (df['tenure_days'] / 30 + 1)  # Normalized by tenure\n",
    "print(\"✅ Created: power_user_score (advanced usage metric)\")\n",
    "\n",
    "### 5. Engagement Velocity\n",
    "### Simulated metric showing trend (in real scenario, compare 30d vs 60d metrics)\n",
    "### For synthetic data, we'll add some variability\n",
    "np.random.seed(42)\n",
    "df['engagement_velocity'] = np.random.uniform(-0.3, 0.3, len(df))\n",
    "### Make it negative for churned customers\n",
    "df.loc[df['churned'] == 1, 'engagement_velocity'] = np.random.uniform(\n",
    "    -0.5, -0.1, (df['churned'] == 1).sum()\n",
    ")\n",
    "print(\"✅ Created: engagement_velocity (trend indicator)\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 3: CUSTOMER HEALTH FEATURES\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 3: CREATING CUSTOMER HEALTH FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nEngineering customer health scores...\")\n",
    "\n",
    "### 1. Overall Health Score (0-100)\n",
    "df['health_score'] = (\n",
    "    ### Engagement component (30 points)\n",
    "    (df['logins_30d'] / df['logins_30d'].max() * 30) +\n",
    "    ### Session quality (20 points)\n",
    "    (df['session_duration_avg'] / df['session_duration_avg'].max() * 20) +\n",
    "    ### Feature adoption (20 points)\n",
    "    (df['features_used'] / df['features_used'].max() * 20) +\n",
    "    ### Sentiment (15 points)\n",
    "    ((df['ticket_sentiment'] + 1) / 2 * 15) +\n",
    "    ### Loyalty (15 points)\n",
    "    (df['net_promoter_score'] / 10 * 15)\n",
    ")\n",
    "print(\"✅ Created: health_score (0-100 composite)\")\n",
    "\n",
    "### 2. Risk Flags\n",
    "### Binary indicators for high-risk behavior\n",
    "df['dormancy_risk'] = (df['days_since_last_login'] > 14).astype(int)\n",
    "df['low_engagement_risk'] = (df['logins_30d'] < 5).astype(int)\n",
    "df['support_risk'] = (df['support_tickets_30d'] > 3).astype(int)\n",
    "df['payment_risk'] = (df['payment_failures'] > 0).astype(int)\n",
    "df['sentiment_risk'] = (df['ticket_sentiment'] < 0).astype(int)\n",
    "\n",
    "### Combined risk flag\n",
    "df['high_risk_flag'] = (\n",
    "    df['dormancy_risk'] |\n",
    "    df['low_engagement_risk'] |\n",
    "    df['support_risk'] |\n",
    "    df['payment_risk']\n",
    ").astype(int)\n",
    "\n",
    "print(\"✅ Created: 6 risk flag features\")\n",
    "\n",
    "### 3. Customer Lifecycle Stage\n",
    "df['lifecycle_stage'] = pd.cut(\n",
    "    df['tenure_days'],\n",
    "    bins=[0, 30, 90, 180, 365, 10000],\n",
    "    labels=['new', 'onboarding', 'growing', 'mature', 'loyal']\n",
    ")\n",
    "print(\"✅ Created: lifecycle_stage (categorical)\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 4: SUPPORT & SATISFACTION FEATURES\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 4: CREATING SUPPORT & SATISFACTION FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nEngineering support interaction features...\")\n",
    "\n",
    "### 1. Support Intensity\n",
    "### Tickets normalized by tenure\n",
    "df['support_intensity'] = df['support_tickets_30d'] / ((df['tenure_days'] / 30) + 1)\n",
    "print(\"✅ Created: support_intensity (tickets per month of tenure)\")\n",
    "\n",
    "### 2. Support Quality Score\n",
    "### Combination of ticket volume and sentiment\n",
    "df['support_quality_score'] = (\n",
    "    (1 - df['support_intensity'].clip(0, 1)) * 0.5 +  # Lower tickets = better\n",
    "    ((df['ticket_sentiment'] + 1) / 2) * 0.5  # Higher sentiment = better\n",
    ") * 100\n",
    "print(\"✅ Created: support_quality_score (0-100)\")\n",
    "\n",
    "### 3. NPS Category\n",
    "df['net_promoter_score_category'] = pd.cut(\n",
    "    df['net_promoter_score'],\n",
    "    bins=[-1, 6, 8, 11],\n",
    "    labels=['detractor', 'passive', 'promoter']\n",
    ")\n",
    "print(\"✅ Created: nps_category (promoter/passive/detractor)\")\n",
    "\n",
    "### 4. Customer Satisfaction Index\n",
    "### Composite of NPS and sentiment\n",
    "df['satisfaction_index'] = (\n",
    "    (df['net_promoter_score'] / 10 * 0.6) +\n",
    "    ((df['ticket_sentiment'] + 1) / 2 * 0.4)\n",
    ") * 100\n",
    "print(\"✅ Created: satisfaction_index (0-100)\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 5: USAGE & VALUE FEATURES\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 5: CREATING USAGE & VALUE FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nEngineering usage and value features...\")\n",
    "\n",
    "### 1. Usage Ratio Categories\n",
    "df['usage_category'] = pd.cut(\n",
    "    df['usage_vs_plan'],\n",
    "    bins=[0, 0.3, 0.6, 1.0],\n",
    "    labels=['low', 'medium', 'high']\n",
    ")\n",
    "print(\"✅ Created: usage_category (low/medium/high)\")\n",
    "\n",
    "### 2. Value Realization Score\n",
    "### How much value customer gets vs pays\n",
    "df['value_realization'] = df['usage_vs_plan'] * df['engagement_score']\n",
    "print(\"✅ Created: value_realization (usage × engagement)\")\n",
    "\n",
    "### 3. Revenue Risk Score\n",
    "### Combines MRR with churn risk indicators\n",
    "df['revenue_risk_score'] = df['monthly_reoccuring_revenue'] * (\n",
    "    df['high_risk_flag'] * 0.5 +\n",
    "    (1 - df['health_score'] / 100) * 0.5\n",
    ")\n",
    "print(\"✅ Created: revenue_risk_score (Monthly Reoccuring Revenue-weighted risk)\")\n",
    "\n",
    "### 4. Customer Lifetime Value (Estimated)\n",
    "### Simple LTV calculation based on MRR and tenure\n",
    "avg_customer_lifetime_months = 24  # assumption\n",
    "df['estimated_ltv'] = df['monthly_reoccuring_revenue'] * avg_customer_lifetime_months * (\n",
    "    1 - (df['high_risk_flag'] * 0.3)  # Discount for high risk\n",
    ")\n",
    "print(\"✅ Created: estimated_ltv (projected lifetime value)\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 6: INTERACTION FEATURES\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 6: CREATING INTERACTION FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nEngineering feature interactions...\")\n",
    "\n",
    "### 1. Engagement × Tenure\n",
    "df['engagement_tenure'] = df['engagement_score'] * np.log1p(df['tenure_days'])\n",
    "print(\"✅ Created: engagement_tenure (engagement × log(tenure))\")\n",
    "\n",
    "### 2. Usage × Satisfaction\n",
    "df['usage_satisfaction'] = df['usage_vs_plan'] * ((df['ticket_sentiment'] + 1) / 2)\n",
    "print(\"✅ Created: usage_satisfaction (usage × sentiment)\")\n",
    "\n",
    "### 3. Logins × Features\n",
    "df['login_feature_interaction'] = df['logins_30d'] * df['features_used']\n",
    "print(\"✅ Created: login_feature_interaction (logins × features)\")\n",
    "\n",
    "### 4. Subscription tier × Engagement\n",
    "### Encode subscription tier first for this calculation\n",
    "subscription_tier_encoding = {'free': 0, 'basic': 1, 'premium': 2}\n",
    "df['subscription_tier_numeric'] = df['subscription_tier'].map(subscription_tier_encoding)\n",
    "df['subscription_tier_engagement'] = df['subscription_tier_numeric'] * df['engagement_score']\n",
    "print(\"✅ Created: subscription_tier_engagement (subscription_tier × engagement)\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 7: TIME-BASED FEATURES\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 7: CREATING TIME-BASED FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nEngineering temporal features...\")\n",
    "\n",
    "### 1. Tenure Segments (more granular)\n",
    "df['tenure_segment'] = pd.cut(\n",
    "    df['tenure_days'],\n",
    "    bins=[0, 30, 60, 90, 180, 365, 730, 10000],\n",
    "    labels=['0-1mo', '1-2mo', '2-3mo', '3-6mo', '6-12mo', '1-2yr', '2yr+']\n",
    ")\n",
    "print(\"✅ Created: tenure_segment (7 categories)\")\n",
    "\n",
    "### 2. Tenure Velocity (value per day)\n",
    "df['tenure_velocity'] = df['engagement_score'] / (df['tenure_days'] + 1)\n",
    "print(\"✅ Created: tenure_velocity (engagement per day)\")\n",
    "\n",
    "### 3. Recent Activity Flag\n",
    "df['recently_active'] = (df['days_since_last_login'] <= 7).astype(int)\n",
    "print(\"✅ Created: recently_active (binary flag)\")\n",
    "\n",
    "### 4. Stale Account Flag\n",
    "df['stale_account'] = (df['days_since_last_login'] > 30).astype(int)\n",
    "print(\"✅ Created: stale_account (binary flag)\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 8: ENCODE CATEGORICAL FEATURES\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 8: ENCODING CATEGORICAL FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nEncoding categorical variables for modeling...\")\n",
    "\n",
    "### 1. Subscription Tier\n",
    "le_tier = LabelEncoder()\n",
    "df['subscription_tier_encoded'] = le_tier.fit_transform(df['subscription_tier'])\n",
    "print(f\"✅ Encoded: subscription_tier → tier_encoded\")\n",
    "print(f\"   Mapping: {dict(zip(le_tier.classes_, le_tier.transform(le_tier.classes_)))}\")\n",
    "\n",
    "### 2. Company Size\n",
    "le_size = LabelEncoder()\n",
    "df['size_encoded'] = le_size.fit_transform(df['company_size'])\n",
    "print(f\"✅ Encoded: company_size → size_encoded\")\n",
    "print(f\"   Mapping: {dict(zip(le_size.classes_, le_size.transform(le_size.classes_)))}\")\n",
    "\n",
    "### 3. Industry\n",
    "le_industry = LabelEncoder()\n",
    "df['industry_encoded'] = le_industry.fit_transform(df['industry'])\n",
    "print(f\"✅ Encoded: industry → industry_encoded\")\n",
    "print(f\"   Mapping: {dict(zip(le_industry.classes_, le_industry.transform(le_industry.classes_)))}\")\n",
    "\n",
    "### 4. Lifecycle Stage\n",
    "le_lifecycle = LabelEncoder()\n",
    "df['lifecycle_encoded'] = le_lifecycle.fit_transform(df['lifecycle_stage'])\n",
    "print(f\"✅ Encoded: lifecycle_stage → lifecycle_encoded\")\n",
    "\n",
    "### 5. NPS Category\n",
    "le_nps = LabelEncoder()\n",
    "df['net_promoter_score_category_encoded'] = le_nps.fit_transform(df['net_promoter_score_category'])\n",
    "print(f\"✅ Encoded: net_promoter_score_category → net_promoter_score_category_encoded\")\n",
    "\n",
    "### 6. Usage Category\n",
    "le_usage = LabelEncoder()\n",
    "df['usage_category_encoded'] = le_usage.fit_transform(df['usage_category'])\n",
    "print(f\"✅ Encoded: usage_category → usage_category_encoded\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 9: FEATURE SUMMARY\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 9: FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "original_features = [\n",
    "    'customer_id', 'signup_date', 'tenure_days', 'subscription_tier',\n",
    "    'monthly_reoccuring_revenue', 'company_size', 'industry', 'logins_30d', 'session_duration_avg',\n",
    "    'features_used', 'power_feature_usage', 'days_since_last_login',\n",
    "    'support_tickets_30d', 'ticket_sentiment', 'net_promoter_score',\n",
    "    'payment_failures', 'usage_vs_plan', 'churned'\n",
    "]\n",
    "\n",
    "new_features = [col for col in df.columns if col not in original_features]\n",
    "\n",
    "print(f\"\\n📊 Feature Engineering Results:\")\n",
    "print(f\"   • Original features: {len(original_features)}\")\n",
    "print(f\"   • New features created: {len(new_features)}\")\n",
    "print(f\"   • Total features: {len(df.columns)}\")\n",
    "\n",
    "print(f\"\\n✨ New Features by Category:\")\n",
    "\n",
    "engagement_features = [f for f in new_features if 'engagement' in f or 'activity' in f or 'usage_efficiency' in f or 'power_user' in f]\n",
    "print(f\"\\n   Engagement Features ({len(engagement_features)}):\")\n",
    "for f in engagement_features:\n",
    "    print(f\"   • {f}\")\n",
    "\n",
    "health_features = [f for f in new_features if 'health' in f or 'risk' in f]\n",
    "print(f\"\\n   Health & Risk Features ({len(health_features)}):\")\n",
    "for f in health_features:\n",
    "    print(f\"   • {f}\")\n",
    "\n",
    "support_features = [f for f in new_features if 'support' in f or 'satisfaction' in f or 'net_promoter_score' in f]\n",
    "print(f\"\\n   Support & Satisfaction Features ({len(support_features)}):\")\n",
    "for f in support_features:\n",
    "    print(f\"   • {f}\")\n",
    "\n",
    "value_features = [f for f in new_features if 'value' in f or 'revenue' in f or 'ltv' in f]\n",
    "print(f\"\\n   Value Features ({len(value_features)}):\")\n",
    "for f in value_features:\n",
    "    print(f\"   • {f}\")\n",
    "\n",
    "interaction_features = [f for f in new_features if 'interaction' in f or f.count('_') > 1]\n",
    "print(f\"\\n   Interaction Features ({len(interaction_features)}):\")\n",
    "for f in interaction_features:\n",
    "    print(f\"   • {f}\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 10: FEATURE CORRELATIONS WITH TARGET\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 10: ANALYZING NEW FEATURE CORRELATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "### Select numeric features only\n",
    "numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_features.remove('churned')\n",
    "\n",
    "### Calculate correlations with churn\n",
    "correlations = df[numeric_features + ['churned']].corr()['churned'].drop('churned')\n",
    "correlations_sorted = correlations.abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n🎯 Top 20 Features by Correlation with Churn:\")\n",
    "print(\"-\" * 70)\n",
    "for i, (feature, corr_value) in enumerate(correlations_sorted.head(20).items(), 1):\n",
    "    actual_corr = correlations[feature]\n",
    "    direction = \"↑\" if actual_corr > 0 else \"↓\"\n",
    "    strength = \"🔴\" if abs(actual_corr) > 0.5 else \"🟡\" if abs(actual_corr) > 0.3 else \"🟢\"\n",
    "    is_new = \"✨ NEW\" if feature in new_features else \"\"\n",
    "    print(f\"{i:2d}. {strength} {feature:35s} {actual_corr:6.3f} {direction} {is_new}\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 11: VISUALIZATIONS\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 11: CREATING FEATURE VISUALIZATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "\n",
    "### 1. Engagement Score Distribution\n",
    "ax1 = axes[0, 0]\n",
    "df[df['churned']==0]['engagement_score'].hist(bins=50, alpha=0.6, label='Retained',\n",
    "                                               ax=ax1, color='#4ECDC4')\n",
    "df[df['churned']==1]['engagement_score'].hist(bins=50, alpha=0.6, label='Churned',\n",
    "                                               ax=ax1, color='#FF6B6B')\n",
    "ax1.set_title('Engagement Score Distribution', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Engagement Score')\n",
    "ax1.legend()\n",
    "\n",
    "### 2. Health Score Distribution\n",
    "ax2 = axes[0, 1]\n",
    "df[df['churned']==0]['health_score'].hist(bins=50, alpha=0.6, label='Retained',\n",
    "                                          ax=ax2, color='#4ECDC4')\n",
    "df[df['churned']==1]['health_score'].hist(bins=50, alpha=0.6, label='Churned',\n",
    "                                          ax=ax2, color='#FF6B6B')\n",
    "ax2.set_title('Health Score Distribution', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Health Score (0-100)')\n",
    "ax2.legend()\n",
    "\n",
    "### 3. Risk Flag Impact\n",
    "ax3 = axes[0, 2]\n",
    "risk_impact = df.groupby('high_risk_flag')['churned'].mean() * 100\n",
    "risk_impact.plot(kind='bar', ax=ax3, color=['#4ECDC4', '#FF6B6B'])\n",
    "ax3.set_title('Churn Rate by Risk Flag', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('Churn Rate (%)')\n",
    "ax3.set_xlabel('High Risk Flag')\n",
    "ax3.set_xticklabels(['No Risk', 'High Risk'], rotation=0)\n",
    "\n",
    "### 4. Lifecycle Stage Impact\n",
    "ax4 = axes[1, 0]\n",
    "lifecycle_churn = df.groupby('lifecycle_stage')['churned'].mean() * 100\n",
    "lifecycle_churn.plot(kind='bar', ax=ax4, color='#033052')\n",
    "ax4.set_title('Churn Rate by Lifecycle Stage', fontsize=12, fontweight='bold')\n",
    "ax4.set_ylabel('Churn Rate (%)')\n",
    "ax4.set_xlabel('Lifecycle Stage')\n",
    "ax4.set_xticklabels(ax4.get_xticklabels(), rotation=45)\n",
    "\n",
    "### 5. Net Promoter Score Category Impact\n",
    "ax5 = axes[1, 1]\n",
    "net_promoter_score_churn = df.groupby('net_promoter_score_category')['churned'].mean() * 100\n",
    "net_promoter_score_churn.plot(kind='bar', ax=ax5, color=['#FF6B6B', '#FFA07A', '#4ECDC4'])\n",
    "ax5.set_title('Churn Rate by Net Promoter Score Category', fontsize=12, fontweight='bold')\n",
    "ax5.set_ylabel('Churn Rate (%)')\n",
    "ax5.set_xlabel('Net Promot Score Category')\n",
    "ax5.set_xticklabels(ax5.get_xticklabels(), rotation=45)\n",
    "\n",
    "### 6. Usage Category Impact\n",
    "ax6 = axes[1, 2]\n",
    "usage_churn = df.groupby('usage_category')['churned'].mean() * 100\n",
    "usage_churn.plot(kind='bar', ax=ax6, color=['#FF6B6B', '#FFA07A', '#4ECDC4'])\n",
    "ax6.set_title('Churn Rate by Usage Category', fontsize=12, fontweight='bold')\n",
    "ax6.set_ylabel('Churn Rate (%)')\n",
    "ax6.set_xlabel('Usage Category')\n",
    "ax6.set_xticklabels(ax6.get_xticklabels(), rotation=45)\n",
    "\n",
    "### 7. Engagement vs Health Score (colored by churn)\n",
    "ax7 = axes[2, 0]\n",
    "scatter = ax7.scatter(df['engagement_score'], df['health_score'],\n",
    "                     c=df['churned'], cmap='RdYlGn_r', alpha=0.5, s=20)\n",
    "ax7.set_title('Engagement vs Health Score', fontsize=12, fontweight='bold')\n",
    "ax7.set_xlabel('Engagement Score')\n",
    "ax7.set_ylabel('Health Score')\n",
    "plt.colorbar(scatter, ax=ax7, label='Churned')\n",
    "\n",
    "### 8. Top 10 Features Correlation Heatmap\n",
    "ax8 = axes[2, 1]\n",
    "top_10 = correlations_sorted.head(10).index.tolist() + ['churned']\n",
    "corr_matrix = df[top_10].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='RdYlGn_r',\n",
    "            center=0, ax=ax8, cbar_kws={'shrink': 0.8})\n",
    "ax8.set_title('Top 10 Features Correlation', fontsize=12, fontweight='bold')\n",
    "\n",
    "### 9. Feature Importance (by correlation)\n",
    "ax9 = axes[2, 2]\n",
    "top_features = correlations_sorted.head(10)\n",
    "y_pos = np.arange(len(top_features))\n",
    "ax9.barh(y_pos, top_features.values, color='#033052')\n",
    "ax9.set_yticks(y_pos)\n",
    "ax9.set_yticklabels(top_features.index, fontsize=8)\n",
    "ax9.set_xlabel('Absolute Correlation')\n",
    "ax9.set_title('Top 10 Features by Correlation', fontsize=12, fontweight='bold')\n",
    "ax9.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../Datasets/feature_engineering_analysis.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\n✅ Saved visualization: ../Datasets/feature_engineering_analysis.png\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 12: SAVE ENGINEERED DATASET\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 12: SAVING ENGINEERED DATASET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "### Save full dataset with all features\n",
    "output_file = '../Datasets/customer_churn_engineered.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\n✅ Saved engineered dataset: {output_file}\")\n",
    "print(f\"   Shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "print(f\"   Size: {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "### Save feature list for modeling\n",
    "modeling_features = [f for f in numeric_features if f not in ['customer_id']]\n",
    "feature_info = {\n",
    "    'all_features': list(df.columns),\n",
    "    'modeling_features': modeling_features,\n",
    "    'categorical_features': ['subscription_tier', 'company_size', 'industry',\n",
    "                            'lifecycle_stage', 'net_promoter_score_category', 'usage_category'],\n",
    "    'encoded_features': ['subscription_tier_encoded', 'size_encoded', 'industry_encoded',\n",
    "                        'lifecycle_encoded', 'net_promoter_score_category_encoded', 'usage_category_encoded'],\n",
    "    'engineered_features': new_features,\n",
    "    'top_features': correlations_sorted.head(20).index.tolist()\n",
    "}\n",
    "\n",
    "import pickle\n",
    "with open('../Datasets/feature_info.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_info, f)\n",
    "print(f\"✅ Saved feature metadata: ../data/feature_info.pkl\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 13: FEATURE RECOMMENDATIONS\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 13: FEATURE SELECTION RECOMMENDATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n📋 Recommended Feature Sets:\")\n",
    "\n",
    "print(\"\\n1️⃣  MINIMAL SET (Top 10 - Quick Model):\")\n",
    "minimal_features = correlations_sorted.head(10).index.tolist()\n",
    "for i, f in enumerate(minimal_features, 1):\n",
    "    print(f\"   {i:2d}. {f}\")\n",
    "\n",
    "print(\"\\n2️⃣  STANDARD SET (Top 20 - Balanced):\")\n",
    "standard_features = correlations_sorted.head(20).index.tolist()\n",
    "print(f\"   {len(standard_features)} features including engagement, health, and risk metrics\")\n",
    "\n",
    "print(\"\\n3️⃣  COMPREHENSIVE SET (All Numeric - Maximum Performance):\")\n",
    "print(f\"   {len(modeling_features)} features - all engineered numeric features\")\n",
    "\n",
    "print(\"\\n4️⃣  INTERPRETABLE SET (Easy to Explain):\")\n",
    "interpretable = [\n",
    "    'health_score', 'engagement_score', 'high_risk_flag',\n",
    "    'days_since_last_login', 'logins_30d', 'support_tickets_30d',\n",
    "    'net_promoter_score', 'usage_vs_plan', 'payment_failures', 'tenure_days'\n",
    "]\n",
    "for i, f in enumerate(interpretable, 1):\n",
    "    print(f\"   {i:2d}. {f}\")\n",
    "\n",
    "### =============================================================================\n",
    "### SUMMARY\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✅ FEATURE ENGINEERING COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "Feature Engineering Summary:\n",
    "  • Original features: {len(original_features)}\n",
    "  • New features created: {len(new_features)}\n",
    "  • Total features: {len(df.columns)}\n",
    "  • Numeric features for modeling: {len(modeling_features)}\n",
    "  \n",
    "Feature Categories Created:\n",
    "  • Engagement metrics: {len(engagement_features)}\n",
    "  • Health & risk indicators: {len(health_features)}\n",
    "  • Support & satisfaction: {len(support_features)}\n",
    "  • Value metrics: {len(value_features)}\n",
    "  • Interaction features: {len(interaction_features)}\n",
    "  \n",
    "Top Predictors Identified:\n",
    "  1. {correlations_sorted.index[0]}: {correlations_sorted.values[0]:.3f}\n",
    "  2. {correlations_sorted.index[1]}: {correlations_sorted.values[1]:.3f}\n",
    "  3. {correlations_sorted.index[2]}: {correlations_sorted.values[2]:.3f}\n",
    "  \n",
    "Files Created:\n",
    "  1. customer_churn_engineered.csv (full dataset)\n",
    "  2. feature_info.pkl (feature metadata)\n",
    "  3. feature_engineering_analysis.png (9 visualizations)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n🚀 Ready for Model Training!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"PART 1: LOADING DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "df = pd.read_csv('../Datasets/customer_churn_data.csv')\n",
    "print(f\"✅ Loaded {len(df):,} customer records\")\n",
    "print(f\"   Original features: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022285f8-ea60-4c09-af3a-42c05e9f85f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
