{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d27a286f-ff64-4564-a21a-44071cbea6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CHURN PREDICTION MODEL TRAINING & EVALUATION\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "PART 1: LOADING ENGINEERED DATA\n",
      "======================================================================\n",
      "âœ… Loaded engineered dataset: 5,000 rows Ã— 54 columns\n",
      "âœ… Loaded 44 features for modeling\n",
      "\n",
      "ðŸ“Š Feature Breakdown:\n",
      "   â€¢ Total features: 54\n",
      "   â€¢ Modeling features: 44\n",
      "   â€¢ Target variable: churned\n",
      "\n",
      "======================================================================\n",
      "PART 2: PREPARING DATA FOR MACHINE LEARNING\n",
      "======================================================================\n",
      "\n",
      "Feature Matrix (X): (5000, 44)\n",
      "Target Vector (y): (5000,)\n",
      "\n",
      "Class Distribution:\n",
      "  â€¢ Retained (0): 3,820 (76.4%)\n",
      "  â€¢ Churned (1): 1,180 (23.6%)\n",
      "\n",
      "âœ… Data Split Complete:\n",
      "   Training set: 4,000 samples (23.6% churn)\n",
      "   Test set: 1,000 samples (23.6% churn)\n",
      "âœ… Features scaled using StandardScaler\n",
      "   (Important for Logistic Regression, not needed for tree-based models)\n",
      "\n",
      "======================================================================\n",
      "PART 3: TRAINING MULTIPLE ML MODELS\n",
      "======================================================================\n",
      "\n",
      "ðŸš€ Training models (this takes ~2-3 minutes)...\n",
      "\n",
      "======================================================================\n",
      "Training: Logistic Regression\n",
      "======================================================================\n",
      "\n",
      "âœ… Training Complete! AUC-ROC: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Retained       1.00      1.00      1.00       764\n",
      "     Churned       1.00      1.00      1.00       236\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "======================================================================\n",
      "Training: Random Forest\n",
      "======================================================================\n",
      "\n",
      "âœ… Training Complete! AUC-ROC: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Retained       1.00      1.00      1.00       764\n",
      "     Churned       1.00      1.00      1.00       236\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "======================================================================\n",
      "Training: Gradient Boosting\n",
      "======================================================================\n",
      "\n",
      "âœ… Training Complete! AUC-ROC: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Retained       1.00      1.00      1.00       764\n",
      "     Churned       1.00      1.00      1.00       236\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "======================================================================\n",
      "Training: XGBoost\n",
      "======================================================================\n",
      "\n",
      "âœ… Training Complete! AUC-ROC: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Retained       1.00      1.00      1.00       764\n",
      "     Churned       1.00      1.00      1.00       236\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "\n",
      "======================================================================\n",
      "PART 4: MODEL PERFORMANCE COMPARISON\n",
      "======================================================================\n",
      "\n",
      "ðŸ† Model Performance Ranking:\n",
      "              Model  AUC Score\n",
      "Logistic Regression        1.0\n",
      "      Random Forest        1.0\n",
      "  Gradient Boosting        1.0\n",
      "            XGBoost        1.0\n",
      "\n",
      "ðŸ¥‡ BEST MODEL: Logistic Regression\n",
      "   AUC Score: 1.0000\n",
      "\n",
      "======================================================================\n",
      "PART 5: DETAILED EVALUATION - BEST MODEL\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š Confusion Matrix:\n",
      "                 Predicted\n",
      "              Retained  Churned\n",
      "Actual Retained    764       0\n",
      "       Churned       0     236\n",
      "\n",
      "ðŸ“ˆ Performance Metrics:\n",
      "  â€¢ Accuracy: 1.000 (100.0% correct overall)\n",
      "  â€¢ Precision: 1.000 (of predicted churns, 100.0% were correct)\n",
      "  â€¢ Recall: 1.000 (caught 100.0% of actual churns)\n",
      "  â€¢ Specificity: 1.000 (correctly identified 100.0% retained)\n",
      "  â€¢ F1-Score: 1.000 (harmonic mean of precision & recall)\n",
      "  â€¢ AUC-ROC: 1.000 (overall ranking ability)\n",
      "\n",
      "ðŸ’¼ Business Impact:\n",
      "  â€¢ Customers flagged as high-risk: 236\n",
      "  â€¢ Actual churners caught: 236 (out of 236 total)\n",
      "  â€¢ False alarms: 0 (0.0% of alerts)\n",
      "  â€¢ Missed churners: 0 (0.0% of churners)\n",
      "\n",
      "ðŸ’° Financial Impact (estimated):\n",
      "  â€¢ Saved revenue: $23,600 (236 customers Ã— $100)\n",
      "  â€¢ Intervention cost: $11,800 (236 interventions Ã— $50)\n",
      "  â€¢ Net benefit: $11,800\n",
      "  â€¢ ROI: 100%\n",
      "\n",
      "======================================================================\n",
      "PART 6: CREATING VISUALIZATIONS\n",
      "======================================================================\n",
      "\n",
      "âœ… Saved: ../data/model_evaluation_comprehensive.png (6 visualizations)\n",
      "\n",
      "======================================================================\n",
      "PART 7: FEATURE IMPORTANCE ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "PART 8: CROSS-VALIDATION FOR ROBUSTNESS CHECK\n",
      "======================================================================\n",
      "\n",
      "Performing 5-fold cross-validation on best model...\n",
      "(This validates model performance is consistent across different data splits)\n",
      "\n",
      "ðŸ“Š Cross-Validation Results:\n",
      "  â€¢ Fold scores: ['1.0000', '1.0000', '0.9996', '1.0000', '1.0000']\n",
      "  â€¢ Mean AUC: 0.9999\n",
      "  â€¢ Std Dev: 0.0002\n",
      "  â€¢ Min: 0.9996 | Max: 1.0000\n",
      "  âœ… Low variance - model is stable!\n",
      "\n",
      "======================================================================\n",
      "PART 9: SAVING MODEL ARTIFACTS\n",
      "======================================================================\n",
      "âœ… Saved model: ../ML Models/churn_model.pkl\n",
      "âœ… Saved scaler: ../ML Models/scaler.pkl\n",
      "âœ… Saved model info: ../ML Models/model_info.pkl\n",
      "âœ… Saved predictions: ../Datasets/test_predictions.csv\n",
      "\n",
      "======================================================================\n",
      "âœ… MODEL TRAINING COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Best Model Performance:\n",
      "  ðŸ¥‡ Model: Logistic Regression\n",
      "  ðŸ“Š AUC-ROC: 1.0000\n",
      "  ðŸŽ¯ Precision: 1.000 (100.0% of alerts are correct)\n",
      "  ðŸŽ¯ Recall: 1.000 (catches 100.0% of churners)\n",
      "  ðŸŽ¯ F1-Score: 1.000\n",
      "  ðŸŽ¯ Accuracy: 1.000\n",
      "  \n",
      "Business Impact:\n",
      "  â€¢ Can identify 100% of churners in advance\n",
      "  â€¢ 0 false positives out of 236 total alerts\n",
      "  â€¢ Estimated net benefit: $11,800\n",
      "  â€¢ ROI: 100%\n",
      "  \n",
      "Cross-Validation:\n",
      "  â€¢ Mean AUC: 0.9999 Â± 0.0002\n",
      "  â€¢ Model is stable âœ…\n",
      "\n",
      "Files Created:\n",
      "  1. churn_model.pkl (trained model)\n",
      "  2. scaler.pkl (feature scaler)\n",
      "  3. model_info.pkl (metadata)\n",
      "  4. test_predictions.csv (test set results)\n",
      "  5. model_evaluation_comprehensive.png (6 charts)\n",
      "  6. feature_importance_detailed.png (top 20 features)\n",
      "\n",
      "\n",
      "ðŸš€ Ready for Model Interpretation!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "### Notebook 4: Model Training & Evaluation\n",
    "### Project: Churn Prevention System\n",
    "### This notebook trains and evaluates machine learning models\n",
    "### NOTE: Run AFTER Notebook 3 (Feature Engineering)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                             roc_auc_score, roc_curve, precision_recall_curve,\n",
    "                             average_precision_score)\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "### Random seed for reproducibility\n",
    "### Why 42? It's a convention (from \"Hitchhiker's Guide to the Galaxy\")\n",
    "### Makes results reproducible - same \"random\" splits every time\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CHURN PREDICTION MODEL TRAINING & EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "### =============================================================================\n",
    "### PART 1: LOAD ENGINEERED DATA\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 1: LOADING ENGINEERED DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "### Load the ENGINEERED dataset (from Notebook 3)\n",
    "df = pd.read_csv('../Datasets/customer_churn_engineered.csv')\n",
    "print(f\"âœ… Loaded engineered dataset: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
    "\n",
    "### Load feature metadata\n",
    "import pickle\n",
    "with open('../Datasets/feature_info.pkl', 'rb') as f:\n",
    "    feature_info = pickle.load(f)\n",
    "\n",
    "modeling_features = feature_info['modeling_features']\n",
    "print(f\"âœ… Loaded {len(modeling_features)} features for modeling\")\n",
    "\n",
    "### Display feature categories\n",
    "print(f\"\\nðŸ“Š Feature Breakdown:\")\n",
    "print(f\"   â€¢ Total features: {len(df.columns)}\")\n",
    "print(f\"   â€¢ Modeling features: {len(modeling_features)}\")\n",
    "print(f\"   â€¢ Target variable: churned\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 2: PREPARE DATA FOR MODELING\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 2: PREPARING DATA FOR MACHINE LEARNING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "### Select features and target\n",
    "X = df[modeling_features].copy()\n",
    "y = df['churned'].copy()\n",
    "\n",
    "print(f\"\\nFeature Matrix (X): {X.shape}\")\n",
    "print(f\"Target Vector (y): {y.shape}\")\n",
    "print(f\"\\nClass Distribution:\")\n",
    "print(f\"  â€¢ Retained (0): {(y==0).sum():,} ({(y==0).mean()*100:.1f}%)\")\n",
    "print(f\"  â€¢ Churned (1): {(y==1).sum():,} ({(y==1).mean()*100:.1f}%)\")\n",
    "\n",
    "### Check for any missing values\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    print(\"\\nâš ï¸ Handling missing values...\")\n",
    "    X = X.fillna(X.median())\n",
    "    print(\"âœ… Missing values filled with median\")\n",
    "\n",
    "### Train-test split with stratification\n",
    "### Stratification ensures both sets have same churn rate\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,         # 80% train, 20% test\n",
    "    random_state=42,       # Reproducibility\n",
    "    stratify=y             # Keep same churn rate in both sets\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Data Split Complete:\")\n",
    "print(f\"   Training set: {X_train.shape[0]:,} samples ({y_train.mean()*100:.1f}% churn)\")\n",
    "print(f\"   Test set: {X_test.shape[0]:,} samples ({y_test.mean()*100:.1f}% churn)\")\n",
    "\n",
    "### Scale features for algorithms that need it\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"âœ… Features scaled using StandardScaler\")\n",
    "print(\"   (Important for Logistic Regression, not needed for tree-based models)\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 3: TRAIN MULTIPLE MODELS\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 3: TRAINING MULTIPLE ML MODELS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "### Define models with hyperparameters\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        random_state=42, \n",
    "        max_iter=1000,\n",
    "        class_weight='balanced'  # Handles class imbalance\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100,        # 100 trees\n",
    "        random_state=42,\n",
    "        max_depth=10,            # Prevents overfitting\n",
    "        min_samples_split=20,    # Min samples to split node\n",
    "        class_weight='balanced'\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        learning_rate=0.1,       # Step size\n",
    "        max_depth=5\n",
    "    ),\n",
    "    'XGBoost': xgb.XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        scale_pos_weight=len(y_train[y_train==0])/len(y_train[y_train==1]),  # Handle imbalance\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"\\nðŸš€ Training models (this takes ~2-3 minutes)...\\n\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Training: {name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    ### Train model\n",
    "    if name == 'Logistic Regression':\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    ### Calculate metrics\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    ### Store results\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'auc_score': auc_score,\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nâœ… Training Complete! AUC-ROC: {auc_score:.4f}\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Retained', 'Churned']))\n",
    "\n",
    "### =============================================================================\n",
    "### PART 4: MODEL COMPARISON\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 4: MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "### Create comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'AUC Score': [results[m]['auc_score'] for m in results.keys()]\n",
    "}).sort_values('AUC Score', ascending=False)\n",
    "\n",
    "print(\"\\nðŸ† Model Performance Ranking:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "### Select best model\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_model = results[best_model_name]['model']\n",
    "best_auc = comparison_df.iloc[0]['AUC Score']\n",
    "\n",
    "print(f\"\\nðŸ¥‡ BEST MODEL: {best_model_name}\")\n",
    "print(f\"   AUC Score: {best_auc:.4f}\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 5: DETAILED EVALUATION OF BEST MODEL\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 5: DETAILED EVALUATION - BEST MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "best_probabilities = results[best_model_name]['probabilities']\n",
    "\n",
    "### Confusion Matrix\n",
    "cm = confusion_matrix(y_test, best_predictions)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(\"\\nðŸ“Š Confusion Matrix:\")\n",
    "print(f\"                 Predicted\")\n",
    "print(f\"              Retained  Churned\")\n",
    "print(f\"Actual Retained   {cm[0,0]:4d}    {cm[0,1]:4d}\")\n",
    "print(f\"       Churned    {cm[1,0]:4d}    {cm[1,1]:4d}\")\n",
    "\n",
    "### Calculate metrics\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Performance Metrics:\")\n",
    "print(f\"  â€¢ Accuracy: {accuracy:.3f} ({accuracy*100:.1f}% correct overall)\")\n",
    "print(f\"  â€¢ Precision: {precision:.3f} (of predicted churns, {precision*100:.1f}% were correct)\")\n",
    "print(f\"  â€¢ Recall: {recall:.3f} (caught {recall*100:.1f}% of actual churns)\")\n",
    "print(f\"  â€¢ Specificity: {specificity:.3f} (correctly identified {specificity*100:.1f}% retained)\")\n",
    "print(f\"  â€¢ F1-Score: {f1:.3f} (harmonic mean of precision & recall)\")\n",
    "print(f\"  â€¢ AUC-ROC: {best_auc:.3f} (overall ranking ability)\")\n",
    "\n",
    "### Business interpretation\n",
    "print(f\"\\nðŸ’¼ Business Impact:\")\n",
    "print(f\"  â€¢ Customers flagged as high-risk: {(best_predictions == 1).sum():,}\")\n",
    "print(f\"  â€¢ Actual churners caught: {tp:,} (out of {tp+fn:,} total)\")\n",
    "print(f\"  â€¢ False alarms: {fp:,} ({fp/(tp+fp)*100:.1f}% of alerts)\")\n",
    "print(f\"  â€¢ Missed churners: {fn:,} ({fn/(tp+fn)*100:.1f}% of churners)\")\n",
    "\n",
    "### Cost-benefit analysis\n",
    "avg_intervention_cost = 50  # $50 per customer intervention\n",
    "avg_customer_value = 100    # $100 Monthly Reoccuring Revenue\n",
    "\n",
    "saved_revenue = tp * avg_customer_value\n",
    "intervention_cost = (tp + fp) * avg_intervention_cost\n",
    "net_benefit = saved_revenue - intervention_cost\n",
    "\n",
    "print(f\"\\nðŸ’° Financial Impact (estimated):\")\n",
    "print(f\"  â€¢ Saved revenue: ${saved_revenue:,} ({tp} customers Ã— ${avg_customer_value})\")\n",
    "print(f\"  â€¢ Intervention cost: ${intervention_cost:,} ({tp+fp} interventions Ã— ${avg_intervention_cost})\")\n",
    "print(f\"  â€¢ Net benefit: ${net_benefit:,}\")\n",
    "print(f\"  â€¢ ROI: {(net_benefit/intervention_cost)*100:.0f}%\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 6: COMPREHENSIVE VISUALIZATIONS (6 CHARTS)\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 6: CREATING VISUALIZATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "### 1. Model Comparison Bar Chart\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "colors = ['#FF6B6B' if i > 0 else '#4ECDC4' for i in range(len(comparison_df))]\n",
    "comparison_df.plot(x='Model', y='AUC Score', kind='barh', ax=ax1, legend=False, color=colors)\n",
    "ax1.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('AUC-ROC Score')\n",
    "ax1.set_xlim(0, 1)\n",
    "for i, v in enumerate(comparison_df['AUC Score']):\n",
    "    ax1.text(v + 0.01, i, f'{v:.4f}', va='center', fontweight='bold')\n",
    "\n",
    "### 2. ROC Curve for all models\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "for name, result in results.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, result['probabilities'])\n",
    "    auc = result['auc_score']\n",
    "    ax2.plot(fpr, tpr, linewidth=2, label=f'{name} (AUC={auc:.3f})')\n",
    "ax2.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
    "ax2.set_title('ROC Curves - All Models', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('False Positive Rate')\n",
    "ax2.set_ylabel('True Positive Rate (Recall)')\n",
    "ax2.legend(loc='lower right', fontsize=9)\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "### 3. Precision-Recall Curve\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "precision_curve, recall_curve, thresholds = precision_recall_curve(y_test, best_probabilities)\n",
    "avg_precision = average_precision_score(y_test, best_probabilities)\n",
    "ax3.plot(recall_curve, precision_curve, linewidth=2, color='#FF6B6B')\n",
    "ax3.fill_between(recall_curve, precision_curve, alpha=0.3, color='#FF6B6B')\n",
    "ax3.set_title(f'Precision-Recall Curve\\n(Avg Precision: {avg_precision:.3f})',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel('Recall (Sensitivity)')\n",
    "ax3.set_ylabel('Precision')\n",
    "ax3.grid(alpha=0.3)\n",
    "\n",
    "### 4. Confusion Matrix Heatmap\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='RdYlGn_r', ax=ax4,\n",
    "            xticklabels=['Retained', 'Churned'],\n",
    "            yticklabels=['Retained', 'Churned'],\n",
    "            cbar_kws={'label': 'Count'})\n",
    "ax4.set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "ax4.set_ylabel('Actual')\n",
    "ax4.set_xlabel('Predicted')\n",
    "\n",
    "### Add percentages as text\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        text_color = 'white' if cm[i, j] > cm.max() / 2 else 'black'\n",
    "        pct = cm[i, j] / cm.sum() * 100\n",
    "        ax4.text(j + 0.5, i + 0.7, f'({pct:.1f}%)', \n",
    "                ha='center', va='center', color=text_color, fontsize=10)\n",
    "\n",
    "### 5. Probability Distribution\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "retained_probs = best_probabilities[y_test == 0]\n",
    "churned_probs = best_probabilities[y_test == 1]\n",
    "ax5.hist(retained_probs, bins=50, alpha=0.6, label='Retained (Actual)', color='#4ECDC4', density=True)\n",
    "ax5.hist(churned_probs, bins=50, alpha=0.6, label='Churned (Actual)', color='#FF6B6B', density=True)\n",
    "ax5.axvline(x=0.5, color='black', linestyle='--', linewidth=2, label='Decision Threshold')\n",
    "ax5.set_title('Predicted Churn Probability Distribution', fontsize=14, fontweight='bold')\n",
    "ax5.set_xlabel('Predicted Churn Probability')\n",
    "ax5.set_ylabel('Density')\n",
    "ax5.legend()\n",
    "ax5.grid(alpha=0.3)\n",
    "\n",
    "### 6. Threshold Analysis (Precision vs Recall tradeoff)\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "### Calculate metrics at different thresholds\n",
    "thresholds_test = np.linspace(0, 1, 100)\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "for thresh in thresholds_test:\n",
    "    y_pred_thresh = (best_probabilities >= thresh).astype(int)\n",
    "    cm_thresh = confusion_matrix(y_test, y_pred_thresh)\n",
    "    if cm_thresh.ravel()[3] + cm_thresh.ravel()[1] > 0:  # Avoid division by zero\n",
    "        prec = cm_thresh.ravel()[3] / (cm_thresh.ravel()[3] + cm_thresh.ravel()[1])\n",
    "        rec = cm_thresh.ravel()[3] / (cm_thresh.ravel()[3] + cm_thresh.ravel()[2])\n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "        if prec + rec > 0:\n",
    "            f1_scores.append(2 * (prec * rec) / (prec + rec))\n",
    "        else:\n",
    "            f1_scores.append(0)\n",
    "    else:\n",
    "        precisions.append(0)\n",
    "        recalls.append(0)\n",
    "        f1_scores.append(0)\n",
    "\n",
    "ax6.plot(thresholds_test, precisions, label='Precision', linewidth=2, color='#4ECDC4')\n",
    "ax6.plot(thresholds_test, recalls, label='Recall', linewidth=2, color='#FF6B6B')\n",
    "ax6.plot(thresholds_test, f1_scores, label='F1-Score', linewidth=2, color='#FFA07A', linestyle='--')\n",
    "ax6.axvline(x=0.5, color='black', linestyle=':', linewidth=2, label='Default Threshold (0.5)')\n",
    "ax6.set_title('Threshold Impact on Metrics', fontsize=14, fontweight='bold')\n",
    "ax6.set_xlabel('Classification Threshold')\n",
    "ax6.set_ylabel('Score')\n",
    "ax6.legend()\n",
    "ax6.grid(alpha=0.3)\n",
    "ax6.set_xlim(0, 1)\n",
    "ax6.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../Datasets/model_evaluation_comprehensive.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\nâœ… Saved: ../data/model_evaluation_comprehensive.png (6 visualizations)\")\n",
    "plt.close()\n",
    "\n",
    "### =============================================================================\n",
    "### PART 7: FEATURE IMPORTANCE ANALYSIS\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 7: FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importances = best_model.feature_importances_\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': modeling_features,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nðŸŽ¯ Top 15 Most Important Features:\")\n",
    "    for i, row in feature_importance.head(15).iterrows():\n",
    "        print(f\"  {i+1:2d}. {row['feature']:40s} {row['importance']:.4f}\")\n",
    "    \n",
    "    ### Visualize top 20\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    top_20 = feature_importance.head(20)\n",
    "    plt.barh(range(len(top_20)), top_20['importance'], color='#45B7D1')\n",
    "    plt.yticks(range(len(top_20)), top_20['feature'])\n",
    "    plt.xlabel('Importance Score', fontsize=12)\n",
    "    plt.title('Top 20 Features for Churn Prediction', fontsize=14, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../Datasets/feature_importance_detailed.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"\\nâœ… Saved: ../data/feature_importance_detailed.png\")\n",
    "    plt.close()\n",
    "\n",
    "### =============================================================================\n",
    "### PART 8: CROSS-VALIDATION\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 8: CROSS-VALIDATION FOR ROBUSTNESS CHECK\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nPerforming 5-fold cross-validation on best model...\")\n",
    "print(\"(This validates model performance is consistent across different data splits)\")\n",
    "\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=5, scoring='roc_auc')\n",
    "\n",
    "print(f\"\\nðŸ“Š Cross-Validation Results:\")\n",
    "print(f\"  â€¢ Fold scores: {[f'{score:.4f}' for score in cv_scores]}\")\n",
    "print(f\"  â€¢ Mean AUC: {cv_scores.mean():.4f}\")\n",
    "print(f\"  â€¢ Std Dev: {cv_scores.std():.4f}\")\n",
    "print(f\"  â€¢ Min: {cv_scores.min():.4f} | Max: {cv_scores.max():.4f}\")\n",
    "\n",
    "if cv_scores.std() < 0.05:\n",
    "    print(f\"  âœ… Low variance - model is stable!\")\n",
    "else:\n",
    "    print(f\"  âš ï¸ High variance - model performance varies across folds\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 9: SAVE MODEL ARTIFACTS\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 9: SAVING MODEL ARTIFACTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "### Save best model\n",
    "model_path = r'../ML Models/churn_model.pkl'\n",
    "joblib.dump(best_model, model_path)\n",
    "print(f\"âœ… Saved model: {model_path}\")\n",
    "\n",
    "### Save scaler\n",
    "scaler_path = r'../ML Models/scaler.pkl'\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"âœ… Saved scaler: {scaler_path}\")\n",
    "\n",
    "### Save comprehensive model info\n",
    "model_info_save = {\n",
    "    'model_type': best_model_name,\n",
    "    'auc_score': best_auc,\n",
    "    'feature_columns': modeling_features,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1_score': f1,\n",
    "    'accuracy': accuracy,\n",
    "    'cv_scores': cv_scores.tolist(),\n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    'threshold': 0.5\n",
    "}\n",
    "\n",
    "info_path = r'../ML Models/model_info.pkl'\n",
    "joblib.dump(model_info_save, info_path)\n",
    "print(f\"âœ… Saved model info: {info_path}\")\n",
    "\n",
    "### Save test predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'customer_id': df.iloc[X_test.index]['customer_id'].values,\n",
    "    'actual_churn': y_test.values,\n",
    "    'predicted_churn': best_predictions,\n",
    "    'churn_probability': best_probabilities\n",
    "})\n",
    "predictions_path = '../Datasets/test_predictions.csv'\n",
    "predictions_df.to_csv(predictions_path, index=False)\n",
    "print(f\"âœ… Saved predictions: {predictions_path}\")\n",
    "\n",
    "### =============================================================================\n",
    "### SUMMARY\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âœ… MODEL TRAINING COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "Best Model Performance:\n",
    "  ðŸ¥‡ Model: {best_model_name}\n",
    "  ðŸ“Š AUC-ROC: {best_auc:.4f}\n",
    "  ðŸŽ¯ Precision: {precision:.3f} ({precision*100:.1f}% of alerts are correct)\n",
    "  ðŸŽ¯ Recall: {recall:.3f} (catches {recall*100:.1f}% of churners)\n",
    "  ðŸŽ¯ F1-Score: {f1:.3f}\n",
    "  ðŸŽ¯ Accuracy: {accuracy:.3f}\n",
    "  \n",
    "Business Impact:\n",
    "  â€¢ Can identify {recall*100:.0f}% of churners in advance\n",
    "  â€¢ {fp:,} false positives out of {tp+fp:,} total alerts\n",
    "  â€¢ Estimated net benefit: ${net_benefit:,}\n",
    "  â€¢ ROI: {(net_benefit/intervention_cost)*100:.0f}%\n",
    "  \n",
    "Cross-Validation:\n",
    "  â€¢ Mean AUC: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}\n",
    "  â€¢ Model is {'stable âœ…' if cv_scores.std() < 0.05 else 'variable âš ï¸'}\n",
    "\n",
    "Files Created:\n",
    "  1. churn_model.pkl (trained model)\n",
    "  2. scaler.pkl (feature scaler)\n",
    "  3. model_info.pkl (metadata)\n",
    "  4. test_predictions.csv (test set results)\n",
    "  5. model_evaluation_comprehensive.png (6 charts)\n",
    "  6. feature_importance_detailed.png (top 20 features)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nðŸš€ Ready for Model Interpretation!\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
