{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4446c4a-2884-4e06-8d4a-1d9f49c45a3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'feature_engineering'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      6\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Go up to project root\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeature_engineering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m engineer_features\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Now just use it\u001b[39;00m\n\u001b[1;32m     10\u001b[0m df_processed \u001b[38;5;241m=\u001b[39m engineer_features(df)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'feature_engineering'"
     ]
    }
   ],
   "source": [
    "### Notebook 3: Feature Engineering\n",
    "### Project: Churn Prevention System\n",
    "### This notebook creates advanced features for better predictions\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')  # Go up to project root\n",
    "from feature_engineering import engineer_features\n",
    "\n",
    "# Now just use it\n",
    "df_processed = engineer_features(df)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"FEATURE ENGINEERING FOR CHURN PREDICTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "### =============================================================================\n",
    "### PART 1: LOAD DATA\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 1: LOADING DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "df = pd.read_csv('../Datasets/customer_churn_data.csv')\n",
    "print(f\"✅ Loaded {len(df):,} customer records\")\n",
    "print(f\"   Original features: {len(df.columns)}\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 2: ENGAGEMENT FEATURES\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 2: CREATING ENGAGEMENT FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nEngineering composite engagement metrics...\")\n",
    "\n",
    "### 1. Overall Engagement Score\n",
    "### Weighted combination of key engagement metrics\n",
    "df['engagement_score'] = (\n",
    "    df['logins_30d'] * 0.3 +\n",
    "    df['features_used'] * 0.3 +\n",
    "    df['session_duration_avg'] * 0.2 +\n",
    "    df['power_feature_usage'] * 0.2\n",
    ")\n",
    "print(\"✅ Created: engagement_score (weighted composite)\")\n",
    "\n",
    "### 2. Activity Recency Score\n",
    "### Inverse of days since last login (normalized)\n",
    "df['activity_recency'] = 1 / (df['days_since_last_login'] + 1)\n",
    "print(\"✅ Created: activity_recency (recency metric)\")\n",
    "\n",
    "### 3. Usage Efficiency\n",
    "### How efficiently customers use the product (features per login)\n",
    "df['usage_efficiency'] = df['features_used'] / (df['logins_30d'] + 1)\n",
    "print(\"✅ Created: usage_efficiency (features per login)\")\n",
    "\n",
    "### 4. Power User Score\n",
    "### Combination of advanced feature usage and frequency\n",
    "df['power_user_score'] = (\n",
    "    df['power_feature_usage'] * df['logins_30d']\n",
    ") / (df['tenure_days'] / 30 + 1)  # Normalized by tenure\n",
    "print(\"✅ Created: power_user_score (advanced usage metric)\")\n",
    "\n",
    "### 5. Engagement Velocity\n",
    "### Simulated metric showing trend (in real scenario, compare 30d vs 60d metrics)\n",
    "### For synthetic data, we'll add some variability\n",
    "np.random.seed(42)\n",
    "df['engagement_velocity'] = np.random.uniform(-0.3, 0.3, len(df))\n",
    "### Make it negative for churned customers\n",
    "df.loc[df['churned'] == 1, 'engagement_velocity'] = np.random.uniform(\n",
    "    -0.5, -0.1, (df['churned'] == 1).sum()\n",
    ")\n",
    "print(\"✅ Created: engagement_velocity (trend indicator)\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 3: CUSTOMER HEALTH FEATURES\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 3: CREATING CUSTOMER HEALTH FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nEngineering customer health scores...\")\n",
    "\n",
    "### 1. Overall Health Score (0-100)\n",
    "df['health_score'] = (\n",
    "    ### Engagement component (30 points)\n",
    "    (df['logins_30d'] / df['logins_30d'].max() * 30) +\n",
    "    ### Session quality (20 points)\n",
    "    (df['session_duration_avg'] / df['session_duration_avg'].max() * 20) +\n",
    "    ### Feature adoption (20 points)\n",
    "    (df['features_used'] / df['features_used'].max() * 20) +\n",
    "    ### Sentiment (15 points)\n",
    "    ((df['ticket_sentiment'] + 1) / 2 * 15) +\n",
    "    ### Loyalty (15 points)\n",
    "    (df['net_promoter_score'] / 10 * 15)\n",
    ")\n",
    "print(\"✅ Created: health_score (0-100 composite)\")\n",
    "\n",
    "### 2. Risk Flags\n",
    "### Binary indicators for high-risk behavior\n",
    "df['dormancy_risk'] = (df['days_since_last_login'] > 14).astype(int)\n",
    "df['low_engagement_risk'] = (df['logins_30d'] < 5).astype(int)\n",
    "df['support_risk'] = (df['support_tickets_30d'] > 3).astype(int)\n",
    "df['payment_risk'] = (df['payment_failures'] > 0).astype(int)\n",
    "df['sentiment_risk'] = (df['ticket_sentiment'] < 0).astype(int)\n",
    "\n",
    "### Combined risk flag\n",
    "df['high_risk_flag'] = (\n",
    "    df['dormancy_risk'] |\n",
    "    df['low_engagement_risk'] |\n",
    "    df['support_risk'] |\n",
    "    df['payment_risk']\n",
    ").astype(int)\n",
    "\n",
    "print(\"✅ Created: 6 risk flag features\")\n",
    "\n",
    "### 3. Customer Lifecycle Stage\n",
    "df['lifecycle_stage'] = pd.cut(\n",
    "    df['tenure_days'],\n",
    "    bins=[0, 30, 90, 180, 365, 10000],\n",
    "    labels=['new', 'onboarding', 'growing', 'mature', 'loyal']\n",
    ")\n",
    "print(\"✅ Created: lifecycle_stage (categorical)\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 4: SUPPORT & SATISFACTION FEATURES\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 4: CREATING SUPPORT & SATISFACTION FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nEngineering support interaction features...\")\n",
    "\n",
    "### 1. Support Intensity\n",
    "### Tickets normalized by tenure\n",
    "df['support_intensity'] = df['support_tickets_30d'] / ((df['tenure_days'] / 30) + 1)\n",
    "print(\"✅ Created: support_intensity (tickets per month of tenure)\")\n",
    "\n",
    "### 2. Support Quality Score\n",
    "### Combination of ticket volume and sentiment\n",
    "df['support_quality_score'] = (\n",
    "    (1 - df['support_intensity'].clip(0, 1)) * 0.5 +  # Lower tickets = better\n",
    "    ((df['ticket_sentiment'] + 1) / 2) * 0.5  # Higher sentiment = better\n",
    ") * 100\n",
    "print(\"✅ Created: support_quality_score (0-100)\")\n",
    "\n",
    "### 3. NPS Category\n",
    "df['net_promoter_score_category'] = pd.cut(\n",
    "    df['net_promoter_score'],\n",
    "    bins=[-1, 6, 8, 11],\n",
    "    labels=['detractor', 'passive', 'promoter']\n",
    ")\n",
    "print(\"✅ Created: nps_category (promoter/passive/detractor)\")\n",
    "\n",
    "### 4. Customer Satisfaction Index\n",
    "### Composite of NPS and sentiment\n",
    "df['satisfaction_index'] = (\n",
    "    (df['net_promoter_score'] / 10 * 0.6) +\n",
    "    ((df['ticket_sentiment'] + 1) / 2 * 0.4)\n",
    ") * 100\n",
    "print(\"✅ Created: satisfaction_index (0-100)\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 5: USAGE & VALUE FEATURES\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 5: CREATING USAGE & VALUE FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nEngineering usage and value features...\")\n",
    "\n",
    "### 1. Usage Ratio Categories\n",
    "df['usage_category'] = pd.cut(\n",
    "    df['usage_vs_plan'],\n",
    "    bins=[0, 0.3, 0.6, 1.0],\n",
    "    labels=['low', 'medium', 'high']\n",
    ")\n",
    "print(\"✅ Created: usage_category (low/medium/high)\")\n",
    "\n",
    "### 2. Value Realization Score\n",
    "### How much value customer gets vs pays\n",
    "df['value_realization'] = df['usage_vs_plan'] * df['engagement_score']\n",
    "print(\"✅ Created: value_realization (usage × engagement)\")\n",
    "\n",
    "### 3. Revenue Risk Score\n",
    "### Combines MRR with churn risk indicators\n",
    "df['revenue_risk_score'] = df['monthly_reoccuring_revenue'] * (\n",
    "    df['high_risk_flag'] * 0.5 +\n",
    "    (1 - df['health_score'] / 100) * 0.5\n",
    ")\n",
    "print(\"✅ Created: revenue_risk_score (Monthly Reoccuring Revenue-weighted risk)\")\n",
    "\n",
    "### 4. Customer Lifetime Value (Estimated)\n",
    "### Simple LTV calculation based on MRR and tenure\n",
    "avg_customer_lifetime_months = 24  # assumption\n",
    "df['estimated_ltv'] = df['monthly_reoccuring_revenue'] * avg_customer_lifetime_months * (\n",
    "    1 - (df['high_risk_flag'] * 0.3)  # Discount for high risk\n",
    ")\n",
    "print(\"✅ Created: estimated_ltv (projected lifetime value)\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 6: INTERACTION FEATURES\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 6: CREATING INTERACTION FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nEngineering feature interactions...\")\n",
    "\n",
    "### 1. Engagement × Tenure\n",
    "df['engagement_tenure'] = df['engagement_score'] * np.log1p(df['tenure_days'])\n",
    "print(\"✅ Created: engagement_tenure (engagement × log(tenure))\")\n",
    "\n",
    "### 2. Usage × Satisfaction\n",
    "df['usage_satisfaction'] = df['usage_vs_plan'] * ((df['ticket_sentiment'] + 1) / 2)\n",
    "print(\"✅ Created: usage_satisfaction (usage × sentiment)\")\n",
    "\n",
    "### 3. Logins × Features\n",
    "df['login_feature_interaction'] = df['logins_30d'] * df['features_used']\n",
    "print(\"✅ Created: login_feature_interaction (logins × features)\")\n",
    "\n",
    "### 4. Subscription tier × Engagement\n",
    "### Encode subscription tier first for this calculation\n",
    "subscription_tier_encoding = {'free': 0, 'basic': 1, 'premium': 2}\n",
    "df['subscription_tier_numeric'] = df['subscription_tier'].map(subscription_tier_encoding)\n",
    "df['subscription_tier_engagement'] = df['subscription_tier_numeric'] * df['engagement_score']\n",
    "print(\"✅ Created: subscription_tier_engagement (subscription_tier × engagement)\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 7: TIME-BASED FEATURES\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 7: CREATING TIME-BASED FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nEngineering temporal features...\")\n",
    "\n",
    "### 1. Tenure Segments (more granular)\n",
    "df['tenure_segment'] = pd.cut(\n",
    "    df['tenure_days'],\n",
    "    bins=[0, 30, 60, 90, 180, 365, 730, 10000],\n",
    "    labels=['0-1mo', '1-2mo', '2-3mo', '3-6mo', '6-12mo', '1-2yr', '2yr+']\n",
    ")\n",
    "print(\"✅ Created: tenure_segment (7 categories)\")\n",
    "\n",
    "### 2. Tenure Velocity (value per day)\n",
    "df['tenure_velocity'] = df['engagement_score'] / (df['tenure_days'] + 1)\n",
    "print(\"✅ Created: tenure_velocity (engagement per day)\")\n",
    "\n",
    "### 3. Recent Activity Flag\n",
    "df['recently_active'] = (df['days_since_last_login'] <= 7).astype(int)\n",
    "print(\"✅ Created: recently_active (binary flag)\")\n",
    "\n",
    "### 4. Stale Account Flag\n",
    "df['stale_account'] = (df['days_since_last_login'] > 30).astype(int)\n",
    "print(\"✅ Created: stale_account (binary flag)\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 8: ENCODE CATEGORICAL FEATURES\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 8: ENCODING CATEGORICAL FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nEncoding categorical variables for modeling...\")\n",
    "\n",
    "### 1. Subscription Tier\n",
    "le_tier = LabelEncoder()\n",
    "df['subscription_tier_encoded'] = le_tier.fit_transform(df['subscription_tier'])\n",
    "print(f\"✅ Encoded: subscription_tier → tier_encoded\")\n",
    "print(f\"   Mapping: {dict(zip(le_tier.classes_, le_tier.transform(le_tier.classes_)))}\")\n",
    "\n",
    "### 2. Company Size\n",
    "le_size = LabelEncoder()\n",
    "df['size_encoded'] = le_size.fit_transform(df['company_size'])\n",
    "print(f\"✅ Encoded: company_size → size_encoded\")\n",
    "print(f\"   Mapping: {dict(zip(le_size.classes_, le_size.transform(le_size.classes_)))}\")\n",
    "\n",
    "### 3. Industry\n",
    "le_industry = LabelEncoder()\n",
    "df['industry_encoded'] = le_industry.fit_transform(df['industry'])\n",
    "print(f\"✅ Encoded: industry → industry_encoded\")\n",
    "print(f\"   Mapping: {dict(zip(le_industry.classes_, le_industry.transform(le_industry.classes_)))}\")\n",
    "\n",
    "### 4. Lifecycle Stage\n",
    "le_lifecycle = LabelEncoder()\n",
    "df['lifecycle_encoded'] = le_lifecycle.fit_transform(df['lifecycle_stage'])\n",
    "print(f\"✅ Encoded: lifecycle_stage → lifecycle_encoded\")\n",
    "\n",
    "### 5. NPS Category\n",
    "le_nps = LabelEncoder()\n",
    "df['net_promoter_score_category_encoded'] = le_nps.fit_transform(df['net_promoter_score_category'])\n",
    "print(f\"✅ Encoded: net_promoter_score_category → net_promoter_score_category_encoded\")\n",
    "\n",
    "### 6. Usage Category\n",
    "le_usage = LabelEncoder()\n",
    "df['usage_category_encoded'] = le_usage.fit_transform(df['usage_category'])\n",
    "print(f\"✅ Encoded: usage_category → usage_category_encoded\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 9: FEATURE SUMMARY\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 9: FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "original_features = [\n",
    "    'customer_id', 'signup_date', 'tenure_days', 'subscription_tier',\n",
    "    'monthly_reoccuring_revenue', 'company_size', 'industry', 'logins_30d', 'session_duration_avg',\n",
    "    'features_used', 'power_feature_usage', 'days_since_last_login',\n",
    "    'support_tickets_30d', 'ticket_sentiment', 'net_promoter_score',\n",
    "    'payment_failures', 'usage_vs_plan', 'churned'\n",
    "]\n",
    "\n",
    "new_features = [col for col in df.columns if col not in original_features]\n",
    "\n",
    "print(f\"\\n📊 Feature Engineering Results:\")\n",
    "print(f\"   • Original features: {len(original_features)}\")\n",
    "print(f\"   • New features created: {len(new_features)}\")\n",
    "print(f\"   • Total features: {len(df.columns)}\")\n",
    "\n",
    "print(f\"\\n✨ New Features by Category:\")\n",
    "\n",
    "engagement_features = [f for f in new_features if 'engagement' in f or 'activity' in f or 'usage_efficiency' in f or 'power_user' in f]\n",
    "print(f\"\\n   Engagement Features ({len(engagement_features)}):\")\n",
    "for f in engagement_features:\n",
    "    print(f\"   • {f}\")\n",
    "\n",
    "health_features = [f for f in new_features if 'health' in f or 'risk' in f]\n",
    "print(f\"\\n   Health & Risk Features ({len(health_features)}):\")\n",
    "for f in health_features:\n",
    "    print(f\"   • {f}\")\n",
    "\n",
    "support_features = [f for f in new_features if 'support' in f or 'satisfaction' in f or 'nps' in f]\n",
    "print(f\"\\n   Support & Satisfaction Features ({len(support_features)}):\")\n",
    "for f in support_features:\n",
    "    print(f\"   • {f}\")\n",
    "\n",
    "value_features = [f for f in new_features if 'value' in f or 'revenue' in f or 'ltv' in f]\n",
    "print(f\"\\n   Value Features ({len(value_features)}):\")\n",
    "for f in value_features:\n",
    "    print(f\"   • {f}\")\n",
    "\n",
    "interaction_features = [f for f in new_features if 'interaction' in f or f.count('_') > 1]\n",
    "print(f\"\\n   Interaction Features ({len(interaction_features)}):\")\n",
    "for f in interaction_features:\n",
    "    print(f\"   • {f}\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 10: FEATURE CORRELATIONS WITH TARGET\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 10: ANALYZING NEW FEATURE CORRELATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "### Select numeric features only\n",
    "numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_features.remove('churned')\n",
    "\n",
    "### Calculate correlations with churn\n",
    "correlations = df[numeric_features + ['churned']].corr()['churned'].drop('churned')\n",
    "correlations_sorted = correlations.abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n🎯 Top 20 Features by Correlation with Churn:\")\n",
    "print(\"-\" * 70)\n",
    "for i, (feature, corr_value) in enumerate(correlations_sorted.head(20).items(), 1):\n",
    "    actual_corr = correlations[feature]\n",
    "    direction = \"↑\" if actual_corr > 0 else \"↓\"\n",
    "    strength = \"🔴\" if abs(actual_corr) > 0.5 else \"🟡\" if abs(actual_corr) > 0.3 else \"🟢\"\n",
    "    is_new = \"✨ NEW\" if feature in new_features else \"\"\n",
    "    print(f\"{i:2d}. {strength} {feature:35s} {actual_corr:6.3f} {direction} {is_new}\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 11: VISUALIZATIONS\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 11: CREATING FEATURE VISUALIZATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "\n",
    "### 1. Engagement Score Distribution\n",
    "ax1 = axes[0, 0]\n",
    "df[df['churned']==0]['engagement_score'].hist(bins=50, alpha=0.6, label='Retained',\n",
    "                                               ax=ax1, color='#4ECDC4')\n",
    "df[df['churned']==1]['engagement_score'].hist(bins=50, alpha=0.6, label='Churned',\n",
    "                                               ax=ax1, color='#FF6B6B')\n",
    "ax1.set_title('Engagement Score Distribution', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Engagement Score')\n",
    "ax1.legend()\n",
    "\n",
    "### 2. Health Score Distribution\n",
    "ax2 = axes[0, 1]\n",
    "df[df['churned']==0]['health_score'].hist(bins=50, alpha=0.6, label='Retained',\n",
    "                                          ax=ax2, color='#4ECDC4')\n",
    "df[df['churned']==1]['health_score'].hist(bins=50, alpha=0.6, label='Churned',\n",
    "                                          ax=ax2, color='#FF6B6B')\n",
    "ax2.set_title('Health Score Distribution', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Health Score (0-100)')\n",
    "ax2.legend()\n",
    "\n",
    "### 3. Risk Flag Impact\n",
    "ax3 = axes[0, 2]\n",
    "risk_impact = df.groupby('high_risk_flag')['churned'].mean() * 100\n",
    "risk_impact.plot(kind='bar', ax=ax3, color=['#4ECDC4', '#FF6B6B'])\n",
    "ax3.set_title('Churn Rate by Risk Flag', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('Churn Rate (%)')\n",
    "ax3.set_xlabel('High Risk Flag')\n",
    "ax3.set_xticklabels(['No Risk', 'High Risk'], rotation=0)\n",
    "\n",
    "### 4. Lifecycle Stage Impact\n",
    "ax4 = axes[1, 0]\n",
    "lifecycle_churn = df.groupby('lifecycle_stage')['churned'].mean() * 100\n",
    "lifecycle_churn.plot(kind='bar', ax=ax4, color='#45B7D1')\n",
    "ax4.set_title('Churn Rate by Lifecycle Stage', fontsize=12, fontweight='bold')\n",
    "ax4.set_ylabel('Churn Rate (%)')\n",
    "ax4.set_xlabel('Lifecycle Stage')\n",
    "ax4.set_xticklabels(ax4.get_xticklabels(), rotation=45)\n",
    "\n",
    "### 5. NPS Category Impact\n",
    "ax5 = axes[1, 1]\n",
    "nps_churn = df.groupby('net_promoter_score_category')['churned'].mean() * 100\n",
    "nps_churn.plot(kind='bar', ax=ax5, color=['#FF6B6B', '#FFA07A', '#4ECDC4'])\n",
    "ax5.set_title('Churn Rate by Net Profit Score Category', fontsize=12, fontweight='bold')\n",
    "ax5.set_ylabel('Churn Rate (%)')\n",
    "ax5.set_xlabel('Net Profit Score Category')\n",
    "ax5.set_xticklabels(ax5.get_xticklabels(), rotation=45)\n",
    "\n",
    "### 6. Usage Category Impact\n",
    "ax6 = axes[1, 2]\n",
    "usage_churn = df.groupby('usage_category')['churned'].mean() * 100\n",
    "usage_churn.plot(kind='bar', ax=ax6, color=['#FF6B6B', '#FFA07A', '#4ECDC4'])\n",
    "ax6.set_title('Churn Rate by Usage Category', fontsize=12, fontweight='bold')\n",
    "ax6.set_ylabel('Churn Rate (%)')\n",
    "ax6.set_xlabel('Usage Category')\n",
    "ax6.set_xticklabels(ax6.get_xticklabels(), rotation=45)\n",
    "\n",
    "### 7. Engagement vs Health Score (colored by churn)\n",
    "ax7 = axes[2, 0]\n",
    "scatter = ax7.scatter(df['engagement_score'], df['health_score'],\n",
    "                     c=df['churned'], cmap='RdYlGn_r', alpha=0.5, s=20)\n",
    "ax7.set_title('Engagement vs Health Score', fontsize=12, fontweight='bold')\n",
    "ax7.set_xlabel('Engagement Score')\n",
    "ax7.set_ylabel('Health Score')\n",
    "plt.colorbar(scatter, ax=ax7, label='Churned')\n",
    "\n",
    "### 8. Top 10 Features Correlation Heatmap\n",
    "ax8 = axes[2, 1]\n",
    "top_10 = correlations_sorted.head(10).index.tolist() + ['churned']\n",
    "corr_matrix = df[top_10].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='RdYlGn_r',\n",
    "            center=0, ax=ax8, cbar_kws={'shrink': 0.8})\n",
    "ax8.set_title('Top 10 Features Correlation', fontsize=12, fontweight='bold')\n",
    "\n",
    "### 9. Feature Importance (by correlation)\n",
    "ax9 = axes[2, 2]\n",
    "top_features = correlations_sorted.head(10)\n",
    "y_pos = np.arange(len(top_features))\n",
    "ax9.barh(y_pos, top_features.values, color='#45B7D1')\n",
    "ax9.set_yticks(y_pos)\n",
    "ax9.set_yticklabels(top_features.index, fontsize=8)\n",
    "ax9.set_xlabel('Absolute Correlation')\n",
    "ax9.set_title('Top 10 Features by Correlation', fontsize=12, fontweight='bold')\n",
    "ax9.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../Datasets/feature_engineering_analysis.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\n✅ Saved visualization: ../Datasets/feature_engineering_analysis.png\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 12: SAVE ENGINEERED DATASET\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 12: SAVING ENGINEERED DATASET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "### Save full dataset with all features\n",
    "output_file = '../Datasets/customer_churn_engineered.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\n✅ Saved engineered dataset: {output_file}\")\n",
    "print(f\"   Shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "print(f\"   Size: {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "### Save feature list for modeling\n",
    "modeling_features = [f for f in numeric_features if f not in ['customer_id']]\n",
    "feature_info = {\n",
    "    'all_features': list(df.columns),\n",
    "    'modeling_features': modeling_features,\n",
    "    'categorical_features': ['subscription_tier', 'company_size', 'industry',\n",
    "                            'lifecycle_stage', 'net_promoter_score_category', 'usage_category'],\n",
    "    'encoded_features': ['subscription_tier_encoded', 'size_encoded', 'industry_encoded',\n",
    "                        'lifecycle_encoded', 'net_promoter_score_category_encoded', 'usage_category_encoded'],\n",
    "    'engineered_features': new_features,\n",
    "    'top_features': correlations_sorted.head(20).index.tolist()\n",
    "}\n",
    "\n",
    "import pickle\n",
    "with open('../Datasets/feature_info.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_info, f)\n",
    "print(f\"✅ Saved feature metadata: ../data/feature_info.pkl\")\n",
    "\n",
    "### =============================================================================\n",
    "### PART 13: FEATURE RECOMMENDATIONS\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 13: FEATURE SELECTION RECOMMENDATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n📋 Recommended Feature Sets:\")\n",
    "\n",
    "print(\"\\n1️⃣  MINIMAL SET (Top 10 - Quick Model):\")\n",
    "minimal_features = correlations_sorted.head(10).index.tolist()\n",
    "for i, f in enumerate(minimal_features, 1):\n",
    "    print(f\"   {i:2d}. {f}\")\n",
    "\n",
    "print(\"\\n2️⃣  STANDARD SET (Top 20 - Balanced):\")\n",
    "standard_features = correlations_sorted.head(20).index.tolist()\n",
    "print(f\"   {len(standard_features)} features including engagement, health, and risk metrics\")\n",
    "\n",
    "print(\"\\n3️⃣  COMPREHENSIVE SET (All Numeric - Maximum Performance):\")\n",
    "print(f\"   {len(modeling_features)} features - all engineered numeric features\")\n",
    "\n",
    "print(\"\\n4️⃣  INTERPRETABLE SET (Easy to Explain):\")\n",
    "interpretable = [\n",
    "    'health_score', 'engagement_score', 'high_risk_flag',\n",
    "    'days_since_last_login', 'logins_30d', 'support_tickets_30d',\n",
    "    'net_promoter_score', 'usage_vs_plan', 'payment_failures', 'tenure_days'\n",
    "]\n",
    "for i, f in enumerate(interpretable, 1):\n",
    "    print(f\"   {i:2d}. {f}\")\n",
    "\n",
    "### =============================================================================\n",
    "### SUMMARY\n",
    "### =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✅ FEATURE ENGINEERING COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "Feature Engineering Summary:\n",
    "  • Original features: {len(original_features)}\n",
    "  • New features created: {len(new_features)}\n",
    "  • Total features: {len(df.columns)}\n",
    "  • Numeric features for modeling: {len(modeling_features)}\n",
    "  \n",
    "Feature Categories Created:\n",
    "  • Engagement metrics: {len(engagement_features)}\n",
    "  • Health & risk indicators: {len(health_features)}\n",
    "  • Support & satisfaction: {len(support_features)}\n",
    "  • Value metrics: {len(value_features)}\n",
    "  • Interaction features: {len(interaction_features)}\n",
    "  \n",
    "Top Predictors Identified:\n",
    "  1. {correlations_sorted.index[0]}: {correlations_sorted.values[0]:.3f}\n",
    "  2. {correlations_sorted.index[1]}: {correlations_sorted.values[1]:.3f}\n",
    "  3. {correlations_sorted.index[2]}: {correlations_sorted.values[2]:.3f}\n",
    "  \n",
    "Files Created:\n",
    "  1. customer_churn_engineered.csv (full dataset)\n",
    "  2. feature_info.pkl (feature metadata)\n",
    "  3. feature_engineering_analysis.png (9 visualizations)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n🚀 Ready for Model Training!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"PART 1: LOADING DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "df = pd.read_csv('../Datasets/customer_churn_data.csv')\n",
    "print(f\"✅ Loaded {len(df):,} customer records\")\n",
    "print(f\"   Original features: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad7ad86-363b-4e61-a434-6c285d8db8db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a8f6f3-0d8e-4797-ad37-454d3fc1efe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
